####调度数据 or 调度计算
    https://mp.weixin.qq.com/s/mN4eQklYJAy4qXK3vhWK3Q
    对于任何一个分布式计算框架而言，如果数据和计算不在同一个节点，那么他们中间必须有一个需要移动到另一个所在的节点
    如果把计算调度到数据所在节点，那就是调度计算，反之则是调度数据，SparkStreaming和Flink的实现是不同的。
    Spark的核心数据结构RDD包含几个关键信息，包括数据的分片（partitions）、依赖（dependencies）等，其中还有
    一个用于优化执行的信息就是preferred locations,这个信息提供了该分片数据的位置信息，即所在的节点，从而提高计算
    效率。
    调度计算的方式在批处理中有很大的优势，因为计算相比数据来讲一般信息量比较小，如果计算可以在数据所在的节点执行，
    会省去大量的网络传输，节省带宽的同时提高计算效率。但在流式计算中，SparkStreaming的调度由于需要频繁的调度计算导致一些
    效率上的损耗。首先计算调度是需要消耗一些时间的，比如计算信息序列化————>传输————>反序列化————>初始化资源————>计算执行————>执行完结果上报等
    都是一些损耗。另外用户的计算中一般会有一些资源的初始化逻辑，比如初始化外部系统的客户端（类似Kafka Producer或Consumer）;每次
    计算的重复调度容易导致这些资源的重复初始化，需要用户对执行逻辑有一定了解才能合理初始化资源，避免资源的重复创建，这就提高了使用门槛。通过
    业务支持发现，在实际生产过程中，经常遇到大并发的SparkStreaming作业给Kafka和Hbase等存储系统带来巨大连接压力就是因为用户在计算逻辑中一直重复创建连接。
    需要指出的是，即使用户代码层面合理使用了一个partition一个连接，但同一个计算逻辑不一定调度到同一个计算节点，还是可能出现
    在不同计算节点上重新创建连接的情况。
    Flink和Storm类似，都是通过调度数据来完成计算的，也就是计算逻辑初始化之并启动之后，如果没有异常会一直执行，源源不断的消费上游的数据，
    有点像工厂里的流水线，货物在传送带上一直传递，每个工人专注完成自己的处理逻辑即可。
    
    虽然调度数据和调度计算各有优势，但在流式计算的实际生产场景中，调度计算很可能有力使不出来，比如一般流式计算都是消费消息队列（比如Kafka）
    的数据进行处理，而实际生产环境中为了保证消息队列的低延迟和易维护，一般不会和计算节点（比如Yarn服务的节点）混部，而是各自的机器，
    所以无论是Spark还是Flink,都无法避免消息队列数据的跨网络传输。所以实际使用体验上讲，Flink的调度数据模式显然消耗更少，计算效率更高，
    同时在使用上更符合用户直觉，不易出现重复创建连接的情况。
    不过值得注意的是，SparkStreaming的调度计算模式，对于计算系统中的慢节点或异常节点有天然的优势。比如Yarn集群中有一台节点
    磁盘存在异常，导致计算不停的失败，Spark可以通过blacklist机制停止调度计算到该节点，从而保证整个作业的稳定性。或者有一台机器
    CPU Load负载偏高，导致处理比较慢，Spark可以通过speculation机制及时把同一计算调度到其它节点，避免慢节点拖慢整个作业，而以上特性在Flink
    中都是缺失的。
    SaprkStreaming并不是真正意义上的流式计算，而实从批处理衍生出来的mini batch计算。Spark 根据RDD依赖关系中的shuffle dependency进行作业的Stage划分，
    每个Stage根据RDD的partition信息切分成不同的分片，在实际执行的时候，只有当每个分片对应的计算结束，整个Stage才算计算完成。这种模式容易出现长尾效应
    ，比如某个分片数据量偏大，那么其它分片也必须等这个分片计算完成后才能进入下一轮计算（spark speculation）对这种情况也没有很好的作用，因为这是由于
    分片数据不均匀导致的，这样既增加了其它分片的数据处理延迟，也浪费了资源。
    而Flink则是为真正的流式计算而设计的，上游数据持续发送到下游，这样就避免了某个长尾分片导致其他分片计算空闲的情况，而实持续在处理数据，这在一定程度上提高了
    计算资源的利用率，降低了延迟
    
    
    
###Flink内存管理
    https://ververica.cn/developers/flink-principle-memory-management/
    如今，大数据领域的开源框架（Hadoop、Spark、Storm）都使用JVM,当然也包括Flink,基于JVM的数据分析引擎都需要面对将大量数据存到内存中，这就不得不面对JVM存在的几个问题：
    1、Java对象存储密度低。一个只包含boolean属性的对象占用16字节内存：对象头8字节，boolean属性1字节，对齐填充7字节。而实际只需要一个bit就够了。
    2、Full GC会极大的影响性能，尤其是为了处理更大数据而开辟了很大内存空间的JVM来说，GC会达到秒级甚至是分钟级。
    3、OOM问题影响稳定性。OutOfMemoryError是分布式计算框架经常会遇到的问题，当JVM中所有对象大小超过分配给JVM的内存大小时，就会发生OutOfMemoryError错误，导致JVM
    崩溃，分布式框架的健壮性和性能都会受到影响。
    所以目前越来越多的大数据项目开始自己管理JVM内存,像Spark、Flink、Hbase，为的就是获得像c一样的性能以及避免OOM。本文将会讨论Flink是如何解决上面的问题，主要内容
    包括内存管理、定制的序列化工具、缓存友好的数据结构和算法、堆外内存、JIT编译优化等。

####积极的内存管理
    Flink并不是将大量对象存在堆上，而是将对象序列化到一个预分配的内存块上，这个内存块叫做MemorySegment,它代表了一段固定长度的内存（默认是32kb）,也是Flink中
    最小的内存分配单元，并且提供了非常高效的读写方法。你可以把MemorySegment想象成Flink定制的java.io.ByteBuffer。它的底层可以是一个普通的java字节数组，也可以是
    一个申请在堆外的byteBuffer,每条记录都会一序列化的形式存储在一个或多个MemorySegment中。
    FlinK中worker名叫TaskManager,是用来运行用户代码的JVM进程。TaskManager的堆外内存主要分成三部分：
    1、Network Buffer:一定数量的32kb大小的buffer,主要用于数据的网络传输。在TaskManager启动的时候就会分配。默认数量是2048个，可以通过taskmanager.network.numberOfBuffer来配置
    2、Memory Manager Pool: 这是一个有MemoryManager管理的，由众多MemorySegment组成的超大集合。Flink中的算法（如sort\shuffle\join）会向这个内存池申请MemorySegment
    3、Remaining (Free) Heap:这部分内存是留给用户代码以及TaskManager的数据结构使用的。因为这些数据结构一般都很小，所以基本这些内存都是给用户代码使用的，从GC的角度
    来看，可以把这里看成是新生代，也就是说这里主要都是用户代码生成的短期对象。
    注意：MemoryManager Pool主要在Batch模式下使用。在Streaming模式下，该池子不会预先分配内存，也不会向该池子请求内存块。也就是说该部分内存都是可以给用户代码使用的。
    不过社区打算在Streaming模式下也能将该池子利用起来。
    Flink采用类似DMBMS的sort和join算法，直接操作二进制数据，从而使序列化/反序列化带来的开销达到最小。所以Flink的内部实现更像是C/C++而非Java。如果需要处理的数据
    超出了内存限制，则会将部分数据存储到硬盘上。如果要操作多块MemorySegment就像操作一块大的连续内存一样，Flink会使用逻辑视图来方便操作。Flink存储序列化数据到内存块，
    在需要的时候将数据存储到磁盘。
    Flink积极的内存管理以及直接操作二进制数据有几点好处：
    1、减少GC压力。所有常驻性数据都是以二进制的形式存储在MemorySegment中，这些MemorySegment一直呆在老年代而不会被GC回收。其他的数据对象基本上是由用户代码生成的
    短生命周期对象，这部分对象可以被Minor GC快速回收。只要用户不去创建大量类似缓存的常驻型对象，那么老年代大小基本不会变，Major GC也就永远不会发生。从而有效降低
    垃圾回收的压力。另外，这里的内存还可以是堆外内存，这可以使得JVM内存更小，从而加速垃圾回收。
    2、避免OOM。所有运行时数据结构和算法只能通过内存池申请内存，保证了其使用的内存大小时固定的，不会因为运行时数据结构和算法而发生OOM,在内存吃紧的情况下，算法（sort\join）
    会高效的将一大批内存块写到磁盘，之后再都回来，因此OOM可以有效的避免。
    3、节省内存空间。Java对象再存储上有很多额外的消耗。如果只存储实际数据的二进制内容，就可以避免这部分消耗。
    4、高效的二进制操作 & 缓存友好的计算。二进制数据以定义好的格式存储，可以高效的比较与操作。另外该二进制可以把相关的值以及hash值、键值和指针等相邻的存放到内存，这使得
    可以对高速缓存更加友好，可以从L1 L2 L3缓存获得性能的提升。
    
    
####Flink量身定制的序列化框架
    目前Java生态提供了众多的序列化框架：Java serialization, Kryo, Apache Avro等。但是Flink实现了自己的序列化框架。因为在Flink中处理的数据流通常是同一类型，
    由于数据集对象的类型固定，对于数据集可以只保存一份对象Schema信息，节省大量的存储空间。同时对于固定大小的类型，也可以通过固定的偏移位置存取。当我们需要访问
    某个对象成员变量的时候，通过定制的序列化工具，并不需要反序列化整个Java对象，而是直接可以通过偏移量，只是反序列化特定的对象成员变量。如果对象的成员变量较多，能大大
    减少Java对象的创建开销，以及内存数据的拷贝大小。
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    